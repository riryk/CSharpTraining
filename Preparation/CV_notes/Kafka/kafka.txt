
1. Kafka batches and partitions. 

For efficiency, messages are written into Kafka in batches. 
A batch is just a collection of messages, 
all of which are being produced to the same topic and partition. 
An individual roundtrip across the network for each message 
would result in excessive over head, 
and collecting messages together into a batch reduces this. 
Of course, this is a tradeoff between latency and throughput

Partitions are also the way that Kafka provides redundancy and scalability. 
Each partition can be hosted on a different server, 
which means that a single topic can be scaled horizontally across multiple servers 
to provide performance far beyond the ability of a single server

The offset is another bit of metadata
—an integer value that continually increases
—that Kafka adds to each message as it is produced. 
Each message in a given partition has a unique offset. 
By storing the offset of the last consumed message for each partition, 
either in Zookeeper or in Kafka itself, 
a consumer can stop and restart without losing its place

Consumers work as part of a consumer group, 
which is one or more consumers that work together to consume a topic.
The group assures that each partition is only consumed by one member.
The mapping of a consumer to a partition is often called 
ownership of the partition by the consumer.

In this way, consumers can horizontally scale to consume topics 
with a large number of messages. 
Additionally, if a single consumer fails, 
the remaining members of the group will rebalance the partitions 
being consumed to take over for the missing member. 

2. Brokers and Clusters

A single Kafka server is called a broker. 
The broker receives messages from producers, assigns offsets to them, 
and commits the messages to storage on disk.

A partition may be assigned to multiple brokers, 
which will result in the partition being replicated (as seen in Figure 1-7). 
This provides redundancy of messages in the partition, 
such that another broker can take over leadership if there is a broker failure. 
However, all consumers and producers operating 
on that partition must connect to the leader.

3. Cross region replication. 

The Kafka project includes a tool called MirrorMaker, used for this purpose. 
At its core, MirrorMaker is simply a Kafka consumer and producer, 
linked together with a queue. 
Messages are consumed from one Kafka cluster and produced for another.

4. Benefits.

Multiple Producers

This makes the system ideal for aggregating data from
many frontend systems and making it consistent. 
For example, a site that serves content to users via a number of microservices 
can have a single topic for page views that
all services can write to using a common format

Multiple Consumers

Kafka is designed for multiple consumers to read
any single stream of messages without interfering with each other. 
This is in contrast to many queuing systems where 
once a message is consumed by one client, 
it is not available to any other.

When coupled with a system to provide message schemas, 
producers and consumers no longer require tight coupling 
or direct connections of any sort. 

Goals for Kafka: 

 - Decouple producers and consumers by using a push-pull model
 - Provide persistence for message data within the messaging system to allow multiple consumers
 - Optimize for high throughput of messages
 - Allow for horizontal scaling of the system to grow as the data streams grew

Many users will have the partition count for a topic be equal to, 
or a multiple of, the number of brokers in the cluster.
This allows the partitions to be evenly distributed to the brokers, 
which will evenly distribute the message load.































 