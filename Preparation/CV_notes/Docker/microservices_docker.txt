
https://udidahan.com/2011/10/02/why-you-should-be-using-cqrs-almost-everywhere/

----------------------------------------------------------------------
1. Containerization?

Containerization is an approach to software development in which an application or service, its 
dependencies, and its configuration (abstracted as deployment manifest files) are packaged together 
as a container image. 
Containers also isolate applications from each other on a shared OS. 
Containerized applications run on top of a container host 
that in turn runs on the OS (Linux or Windows).

Another benefit of containerization is scalability. 
You can scale out quickly by creating new containers for short-term tasks. 
From an application point of view, instantiating an image (creating a container) 
is similar to instantiating a process like a service or web app

The most important benefit is the isolation provided between Dev and Ops.
Docker is an open-source project for automating the deployment of applications as portable, 
self-sufficient containers that can run on the cloud or on-premises.

--------------------------------------------------------------------
2. Choose .NET Core vs .NET Framework? 

You should use .NET Core for your containerized Docker server application when:
  • You have cross-platform needs. For example, 
    you want to use both Linux and Windows Containers.
  • Your application architecture is based on microservices.
  • You need to start containers fast and want a small footprint per container 
    to achieve better density or more containers per hardware unit in order to lower your costs
	
You should use .NET Framework for your containerized Docker server application when:
  • Your application currently uses .NET Framework and has strong dependencies on Windows.
  • You need to use Windows APIs that are not supported by .NET Core.
  • You need to use third-party .NET libraries or NuGet packages that are not available for .NET Core.

In contrast, to use .NET Framework for a container, you must base your image on the Windows Server Core image, 
which is a lot heavier than the Windows Nano Server or Linux images that you use for .NET Core. 

Additionally, .NET Core is cross-platform, so you can deploy server apps 
with Linux or Windows container images. 
However, if you are using the full .NET Framework, 
you can only deploy images based on Windows Server Core

A microservice is meant to be as small as possible: 
 to be light when spinning up, to have a small footprint, to have a small Bounded Context, 
 to represent a small area of concerns, and to be able to start and stop fast

You can run your system with a much lower number of servers or VMs, 
ultimately saving costs in infrastructure and hosting.

Improve your DevOps workflow with Docker—containers can give you better isolated test environments 
and can also eliminate deployment issues caused by missing dependencies 
when you move to a production environment. 
In cases like these, even if you are deploying a monolithic application, 
it makes sense to use Docker and Windows Containers for your current .NET Framework applications.

With the .NET Standard Library 2.0, this will be even easier, 
because the .NET Core API surface will become significantly bigger. 
Your .NET Core applications will be able to directly use existing .NET Framework libraries.

these versions of Windows provide different characteristics 
(like IIS versus a self-hosted web server like Kestrel) 

When building Docker images for developers, Microsoft focused on the following main scenarios:
• Images used to develop and build .NET Core apps.
• Images used to run .NET Core apps.

----------------------------------------------------------
3. Containerizing monolithic applications

This monolithic pattern might conflict with the container principle 
“a container does one thing, and does it in one process”.

However, in most cases, just a few parts of the 
application are the choke points that requiring scaling, 
while other components are used less. 

But, in addition to the problem of scaling all components, 
changes to a single component require complete retesting of the entire application, 
and a complete redeployment of all the instances.

------------------------------------------------------------
4. SOA

SOA means that you structure your application by decomposing it into multiple services 
(most commonly as HTTP services) 
that can be classified as different types like subsystems or tiers.

Features like big central brokers, central orchestrators at the organization level, 
and the Enterprise Service Bus (ESB) are typical in SOA

Each microservice implements a specific end-to-end domain or business capability 
within a certain context boundary, and each must be 
developed autonomously and be deployable independently. 
Finally, each microservice should own its related domain data model and domain logic.

Create loosely coupled services so you have autonomy of development, deployment, and scale, for each service.
More important than the size of the 
microservice is the internal cohesion it must have 
and its independence from other services.

Microservices enable better maintainability in complex, large, 
and highly-scalable systems by letting you create applications based 
on many independently deployable services that each have granular and autonomous lifecycles.

As an additional benefit, microservices can scale out independently. 
Instead of having a single monolithic application that you must scale out as a unit, 
you can instead scale out specific microservices.

----------------------------------------------
ACID 

But distributed data structures mean that you cannot make a single ACID transaction across microservices. 
This in turn means you must use eventual consistency when a business process spans multiple microservices. 
This is much harder to implement than simple SQL joins; 
similarly, many other relational database features are not available across multiple microservices.

Atomicity guarantees that each transaction is treated as a single "unit", 
          which either succeeds completely or fails completely:
          An atomic system must guarantee atomicity in each and every situation, 
		  including power failures, errors, and crashes.		  

Consistency ensures that a transaction can only bring the database from one consistent state to another, 
            preserving database invariants: any data written to the database 
			must be valid according to all defined rules, including constraints, cascades, triggers, 
			and any combination thereof
			
Isolation Transactions 
          are often executed concurrently (e.g., multiple transactions reading and writing to a table at the same time). 
		  Isolation ensures that concurrent execution of transactions leaves the database 
		  in the same state that would have been obtained if the transactions were executed sequentially. 
		  Isolation is the main goal of concurrency control; 
		  depending on the isolation level used, the effects of an incomplete transaction 
		  might not be visible to other transactions.

Durability guarantees that once a transaction has been committed, it will remain committed 
           even in the case of a system failure (e.g., power outage or crash). 
		   This usually means that completed transactions (or their effects) are recorded in non-volatile memory.

A microservice is therefore like a Bounded Context, 
but it also specifies that it is a distributed service. 
It is built as a separate process for each Bounded Context.

-------------------------------------------------------
Logical architecture versus physical architecture

Challenge #1: How to define the boundaries of each microservice
  For instance, a user can be referred as a user in the identity or membership context, 
  as a customer in a CRM context, as a buyer in an ordering context, and so forth. 
  
Challenge #2: How to create queries that retrieve data from several microservices  
  An example could be a single screen from a mobile app that needs 
  to show user information that is owned by the basket, catalog, and user identity microservices.
  Another example would be a complex report involving many tables located in multiple microservices.
  
  API Gateway.
    For simple data aggregation from multiple microservices that own different databases, 
    the recommended approach is an aggregation microservice referred to as an API Gateway  

  Materialized View pattern
    When the source data for the view changes, 
	the view must be updated to include the new information. 
	You can schedule this to happen automatically, 
	or when the system detects a change to the original data. 
	In some cases it might be necessary to regenerate the view manually
	
  CQRS with query/reads tables.
    In this approach, you generate, in advance 
	(prepare denormalized data before the actual queries happen)
	You can address the requirement using a CQRS approach—
	you create a denormalized table in a different database that is used just for queries.
	it also improves performance considerably when compared with a complex join, 
	because you already have the data that the application needs in the query table. 
	
  “Cold data” in central databases.
    A common approach is to export your “hot data” (transactional data from the microservices) 
	as “cold data” into large databases that are used only for reporting.
	That central database system can be a Big Data-based system, like Hadoop, 
	a data warehouse like one based on Azure SQL Data Warehouse
	
	However, if your application design involves constantly aggregating information 
	from multiple microservices for complex queries, it might be a symptom of a bad design—
	a microservice should be Architecting Container- 
	and Microservice-Based Applications as isolated as possible from other microservices. 
	(This excludes reports/analytics that always should use cold-data central databases.) 
	
	Having this problem often might be a reason to merge microservices. 
	You need to balance the autonomy of evolution and deployment 
	of each microservice with strong dependencies, cohesion, and data aggregation.

Challenge #3: How to achieve consistency across multiple microservice
    Use Case. ECommerce web site. 
     Price is changed in Catalog Microservice. 
	 In Basket microservice we need to update price and show user a new price. 
	 Catalog puts message to queue for Basket. Eventual Consistency. 

Challenge #4: How to design communication across microservice boundaries
     But if create long chains of synchronous HTTP calls across microservices, 
     communicating across their boundaries as if the microservices were objects in a monolithic 
     application, your application will eventually run into problems
	 
	 - Imagine if the number of these calls increases significantly 
	   and at the same time one of the intermediate HTTP calls to a microservice is blocked.
	 - Business microservices should not be coupled with other business microservices. 
	   Ideally, they should not “know” about the existence of other microservices
	 - Failure in any one microservice. 
	   If you implemented a chain of microservices linked by HTTP calls, 
	   when any of the microservices fails (and eventually they will fail) 
	   the whole chain of microservices will fail. 
	   A microservice-based system should be designed to continue to work as well as possible during partial failures
	   
	It could be argued that you have a monolithic application, 
	but one based on HTTP between processes instead of intraprocess communication mechanisms.    
	
Identifying domain-model boundaries for each microservice
Direct client-to-microservice communication   
Using an API Gateway  
 Drawbacks of the API Gateway pattern: 
   1. The most important drawback is that when you implement an API Gateway, you are coupling 
      that tier with the internal microservices. New ESB. 
   2. Using a microservices API Gateway creates an additional possible point of failure.
   3. An API Gateway can introduce increased response time due to the additional network call. 
      However, this extra call usually has less impact than having a client interface that is too chatty 
      directly calling the internal microservices.
   4. The API Gateway can represent a possible bottleneck if it is not scaled out properly
   5. An API Gateway requires additional development cost and future maintenance 
      if it includes  custom logic and data aggregation.
   6. If the API Gateway is developed by a single team, there can be a development bottleneck. 
      This is another reason why a better approach is to have several fined-grained API Gateways 
	  that respond to different client needs.

Communication between microservices
 1. A direct conversion from in-process method calls into RPC calls to services 
    will cause a chatty and not efficient communication 
	that will not perform well in distributed environments.
	
Multiple-receivers message-based communication
 Thus, it helps you to follow the open/closed principle in the sending service. 
 That way, additional subscribers can be added in the future without the need to modify the sender service.
 
Resiliently publishing to the event bus: 
  1. Using a transactional (DTC-based) queue like MSMQ. (However, this is a legacy approach.)
  2. Using transaction log mining
      https://pradeepl.com/blog/transactional-outbox-pattern/
      https://microservices.io/patterns/data/transaction-log-tailing.html 	  
	

   




 
 



	 
	 
	




	
	
  
  
  
		  


 

























 
 





  
  
	